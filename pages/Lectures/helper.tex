\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
    \usepackage{xeCJK}
    \setCJKmainfont[]{Noto Sans CJK JP}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={にほんご},
            pdfauthor={Yufree},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{にほんご}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Yufree}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2016-09-19}


\begin{document}
\maketitle

\subsection{にほんご}

これは日本で はじめに
先日、知人が社労士の試験を受けていたのですが、アプリで問題を色々と解けるものがあるらしく、少しの課金で通勤電車などでの勉強が捗るそうです。統計検定に関してもそのようなものがあればいいなとは思いますが、そんなものを作る気力はないので、よくある分布とその平均と分散に関する導出についてひたすら記していきます。これで少なくとも自分の通勤時の学習が捗ると思われます。なによりも、歳をとっても最低限の数式を扱うスキルがあれば思い出せるレベルで残すことも意識したいですね。

※PC版でないと数式が切れてしまうので、SP版での閲覧はおすすめしません。

今回登場する離散分布
『数理統計学―基礎から学ぶデータ解析』という本に登場するものを式を補いながら紹介します。

1.一様分布 2.ベルヌーイ分布 3.二項分布 4.ポアソン分布 5.超幾何分布
6.幾何分布 7.負の二項分布 1.一様分布
確率変数が有限個の値をとり、それぞれの確率が\[\frac{1}{n}\]である分布。

一様分布の平均 \[E(X)=\frac{1}{n}\sum_{i=1}^{n}X_{i}\]

一様分布の分散 \[V(X)=\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\bar X)^2\]

2.ベルヌーイ分布
等確率の原理に従うとして、あるトラックの中にある「ちくわぶ」を取り出していった場合、確率θで「ちくわぶ」は穴が空いておらず、確率(1-θ)で穴が空いているとする。穴の空いていない「ちくわぶ」の割合はベルヌーイ分布に従う。

ベルヌーイ分布の平均 \[E(X)=1 \times \theta + 0 \times (1-\theta ) \ \]
\[ = \theta \]

ベルヌーイ分布の分散
\[V(X)=(1-\theta)^2 \times \theta + (0 – \theta)^2 \times (1-\theta ) \ \]
\[ = \left[ (1-\theta) \times \theta + \theta^2 \right] \times (1-\theta) \]
\[ = \theta(1-\theta) \]

3.二項分布
一つの事象（「ちくわぶ」に穴が空いているかどうか）に関する、確率θからなるベルヌーイ分布に従う確率変数列を
\[X_1 , X_2, \dots ,X_n\]
として、それらの和（n回試行した際の「ちくわぶ」に穴が空いていない個数）を
\[X = X_1 + X_2 + \dots + X_n\]
とする。その和の従う確率分布は二項分布と呼ばれ、
\[P(X=x):= {}_n C_x \theta^x(1-\theta)^{n-x}\] と表される。

二項分布の平均
\[E(X)=\sum_{x=0}^{n}x \times {}_n C_x \theta^x(1-\theta)^{n-x} \]

x=0のときは0なので、

\[ = \sum_{x=1}^{n} \frac{n!}{(n-x)!(x-1)!}\theta^x(1-\theta)^{n-x}\]
\[ = n \theta \sum_{x=1}^{n} \frac{(n-1)!}{(n-x)!(x-1)!}\theta^{x-1}(1-\theta)^{n-x}\]
\[ = n \theta \sum_{x=1}^{n} \frac{(n-1)!}{\left[ (n-1) – (x-1) \right]!(x-1)!}\]
\[ \times \theta^{x-1}(1-\theta)^{ (n-1) – (x-1) } \] ここで \[y = x-1\]
とおくと、

\[ = n \theta \sum_{y=0}^{n-1} {}_{n-1} C_y \theta^y(1-\theta)^{n-1-y}\]
二項分布の和は1であるという性質を使えば、 \[ = n \theta \]

二項分布の分散
\[E[X(X-1)] = \sum_{x=0}^{n} x(x-1) {}_n C_x \theta^x(1-\theta)^{n-x} \]

x = 1, 2のときは0なので、

\[= \sum_{x=2}^{n} \frac{n!}{(n-x)!(x-2)!} \theta^x(1-\theta)^{n-x} \]
\[= \sum_{x=2}^{n} \frac{n!}{\left[ (n-2) – (x-2) \right]!(x-2)!} \theta^x(1-\theta)^{(n-2) – (x-2) } \]
\[= n(n-1)\theta^2 \sum_{x=2}^{n} \frac{n!}{\left[ (n-2) – (x-2) \right]!(x-2)!} \theta^{x-2}(1-\theta)^{(n-2) – (x-2) } \]
ここで \[y = x -2\] とおくと、
\[= n(n-1)\theta^2 \sum_{y=0}^{n-2} {}_{n-2} C_y \theta^y(1-\theta)^{(n-2) – y } \]
となり、二項分布の和が1であることから、 \[= n(n-1)\theta^2\] となる。

\[V(X)=E(X^2)-[ E(X) ]^2\] \[ =E[X(X-1)] + E(X) -[ E(X) ]^2\]
\[ =n(n-1)\theta^2 + n \theta -[ n \theta ]^2\] \[ =n\theta(1-\theta)\]

また、この式より、二項分布に関してはθの絶対値が1よりも小さいことから、平均よりも分散の方が小さくなることがわかる。

4.ポアソン分布 二項分布において、平均値がλとおく。つまり、
\[n\theta = \lambda\]
λが一定でnが非常に大きいケースにおいて、その確率分布はポアソン分布に従う。λが一定でnが非常に大きいケースというのは、θが非常に小さいということになり、その事象が滅多に起きないような対象に対して扱われることが多い。

ポアソン分布の導出は二項分布からネイピア数を用いて導出する方法や、微分方程式を用いた方法などがある。

ポアソン分布の導出（二項分布からver）
\[{}_{n} C_x \theta^x(1-\theta)^{n-x}\]
\[ = \frac{n(n-1) \dots (n-x+1)}{x!} \theta^x(1-\theta)^{n-x}\]

ここで、 \[\theta = \frac{\lambda}{n}\] とすると
\[ = \frac{1\left(1-\frac{1}{n}\right) \dots \left(1-\frac{x-1}{n}\right)}{x!} \left(\frac{\lambda}{n}\right)^x\left(1-\frac{\lambda}{n}\right)^{n-x}n^x\]
\[ = \frac{1\left(1-\frac{1}{n}\right) \dots \left(1-\frac{x-1}{n}\right)}{x!} \lambda^x\left(\left(1-\frac{\lambda}{n}\right)^{-\frac{n}{\lambda}}\right)^{-\lambda} \left(1-\frac{\lambda}{n}\right)^{-x}\]

nを無限大にすると、分母にのみnがある項は0になり、また、ネイピア数の定義から
\[ \lim_{n\to\infty}{}_{n} C_x \theta^x(1-\theta)^{n-x} = \frac{\lambda^x e^{-\lambda}}{x!}\]
となる。 \[P(X=x):= \frac{\lambda^x e^{-\lambda}}{x!}\]
この確率分布がポアソン分布と呼ばれる。（x=0,1,2,\ldots{}）

実際に、確率分布の性質を確かめると、

\[ \sum_{x=0}^{\infty} P(X=x) = \sum_{x=0}^{\infty} \frac{\lambda^x e^{-\lambda}}{x!} \]
\[ = e^{-\lambda} \sum_{x=0}^{\infty} \frac{\lambda^x}{x!} \]
指数の和の公式より、 \[ = e^{-\lambda} e^{\lambda} = 1 \]
よって、確率分布であることがわかる。

ポアソン分布の導出（微分方程式ver）
abrahamcowさんのブログにまさにそれが書かれていました。図も載っていて詳しくて良いです。
他にも、英語の文献だとA Quick Way to See that the Poisson Distribution
is the Appropriate Mathematical Formulation for a Counting Process with
Constant Rate and Intensityなどがあります。

これらの文献を見ていただければ導出について理解できると思います。

以下、これらの文献を参考にして式展開したものを記しておきます。

まず、3つの仮定をおきます。

1.互いに背反する期間では現象が起こる確率は独立。
つまり、X(t)とX(t+h)-X(t)は独立。
2.非常に小さい区間で現象が起こる確率はその区間の長さに比例する。
\[P\{X(t+h) – X(t) = 1 \} = \lambda h + o(h)\] ここでo(h)は
\[\lim_{n\to 0} \frac{o(h)}{h}=0\] となる関数とする。また、λ
\textgreater{} 0とする。
3.非常に小さい区間で現象が2回以上起こる確率はその区間で現象が1回起こる確率に比べて、無視できるほど小さい。
\[P\{X(t+h) – X(t) = k\} = o(h) \] ただし、k \textgreater{} 1とする。
ここで、X(t)がrになる確率を以下の表現で表す。
\[P_r (t) = P\{ X(t) = r \} \]

事象 \[X(t+h)=r\] は以下の3つに場合分けできる。

1.\[ \{ X(t) = r,X(t+h) – X(t) = 0 \}\] この \[X(t+h) – X(t) = 0\]
は仮定2と仮定3の式を1から差っ引いたものによって確率を計算できる。また、仮定1から互いに背反する期間では現象が起こる確率は独立のため、同時確率は各々の積で表される。
\[P\{ X(t) = r \} (1 – \lambda h – o(h) – o(h) )\]

2.\[ \{ X(t) = r-1,X(t+h) – X(t) = 1 \}\] 仮定2より、
\[P\{ X(t) = r-1 \} (\lambda h + o(h))\] によって表される。
3.\[ \{ X(t+h) = r-k,X(t+h) – X(t) = k \} , k > 1 \] 仮定3より、
\[P\{ X(t+h) = r-k \} o(h)\] によって表される。

これらは期間が違うため、仮定より互いに背反であることから、3つに場合分けの確率の和で表現する。
\[P_r(t+h) = P\{ X(t) = r \} \]
\[= P\{ X(t) = r \} (1 – \lambda h – o(h) – o(h) ) \]
\[+ P\{ X(t) = r-1 \} (\lambda h + o(h)) + P\{ X(t+h) = r-k \} o(h)\]

\[= P_r(t)(1-\lambda h) + P_{r-1}(t)\lambda h + o(h) \]

\[P_r(t+h) – P_r(t) = -\lambda h P_r(t) + P_{r-1}(t)\lambda h + o(h) \]

\[\frac{P_r(t+h) – P_r(t)}{h} = -\lambda P_r(t) + \lambda P_{r-1}(t) + \frac{o(h)}{h} \]
hの極限をとると、
\[\lim_{h\to 0} \frac{P_r(t+h) – P_r(t)}{h} = -\lambda P_r(t) + \lambda P_{r-1}(t) \]
となる。

これらは r = 0のとき \[\frac{P_0(t)}{dt} = – \lambda P_0(t)\]

r ≠ 0のとき
\[\frac{P_r(t)}{dt} = -\lambda P_r(t) + \lambda P_{t-1}(t), r = 1,2,\dots\]

となる微分方程式として表される。

まず、r=0の場合の微分方程式を解くと、

\[\frac{P_0(t)}{dt} = – \lambda P_0(t) \Rightarrow \frac{d P_0(t)}{P_0(t)} = -\lambda dt \]
両辺積分すると、 \[ \int \frac{d P_0(t)}{P_0(t)} = -\lambda \int dt \]

\[ \log P_0(t) = -\lambda t + C\] （Cは積分定数）

\[P_0(t) = e^{-\lambda t +C}\] Cは任意なので、 \[e^C=C\] として、
\[P_0(t) = Ce^{-\lambda t}\] となる。 t =
0で1件も発生しない確率は1なので、 \[P_0(0)=C=1\] から、C =
1であることがわかり、 \[P_0(t) = e^{-\lambda t}\] となる。

ここで、定数係数の1階線形微分方程式の解の公式は、
\[y^{\prime} + p(x)y = q(x)\] に対して、
\[y = e^{-p(x)x}\left[ \int q(x) e^{p(x)x}dx + C \right]\] で表される。
この解の公式を今回のr=1の場合の微分方程式に当てはめると、
\[y^{\prime} = P_1(t) , p(x) = -\lambda , q(x) = \lambda P_0(t) \]
であるから、
\[P_1(t) = e^{-\lambda t}\left[ \int \lambda P_0(t) e^{\lambda t} dt + C \right] \]
となる。ここに、𝑃0(𝑡)を代入すると、
\[ = e^{-\lambda t}\left[ \int \lambda e^{-\lambda t} e^{\lambda t} dt \right] \]
\[ = e^{-\lambda t}\left[ \int \lambda dt + C \right] \]
\[ = e^{-\lambda t} \lambda t + e^{-\lambda t}C \] となる。
t=0においてX(0)=1の確率は0なので、C=0となり、
\[P_1(t) = e^{-\lambda t} \lambda t \]

同様にしてr=2の場合、
\[P_2(t) = \frac{e^{-\lambda t \left( \lambda t \right)^2}}{2} \]
r=3の場合、
\[P_3(t) = \frac{e^{-\lambda t \left( \lambda t \right)^3}}{2 \times 3} \]
となる。

ここで、任意の整数r=kにおいて、
\[P_k(t) = \frac{e^{\lambda t} \left( \lambda t \right)^k }{k!}\]
が成り立つとする。

r=k+1のとき、
\[P_{k+1}(t) = \frac{e^{\lambda t} \left( \lambda t \right)^{k+1} }{(k+1)!}\]
である。
これはポアソン分布であり、定数係数の1階線形微分方程式よりポアソン分布が導出できることが示された。

ポアソン分布の平均
\[E(X)=\sum_{x=0}^{\infty}x \frac{e^{-\lambda}\lambda^x}{x!}\]
\[ =\sum_{x=0}^{\infty} \frac{e^{-\lambda}\lambda^x}{(x-1)!}\]
\[ =\lambda \sum_{x=1}^{\infty} \frac{e^{-\lambda}\lambda^{x-1}}{(x-1)!} = \lambda \]

ポアソン分布の分散
\[E(X(X-1)) = \sum_{x=0}^{\infty}x(x-1) \frac{e^{-\lambda}\lambda^x}{x!}\]
\[ = \sum_{x=0}^{\infty} \frac{e^{-\lambda}\lambda^x}{(x-2)!}\]
\[ = \lambda^2 \sum_{x=2}^{\infty} \frac{e^{-\lambda}\lambda^{x-2}}{(x-2)!} =\lambda^2 \]

\[V(X)=E(X^2)-[ E(X) ]^2\] \[ =E[X(X-1)] + E(X) -[ E(X) ]^2\]
\[ = \lambda^2 + \lambda – \lambda^2 = \lambda \]

ポアソン分布の再生性
XとYは独立にそれぞれポアソン分布λ1とλ2に従うとする。
\[P(Z=z) = \sum_{x=0}^{z} P(X=x, Y=z-x) \]
\[ = \sum_{x=0}^{z} P(X=x)P(Y=z-x) \]
\[ = \sum_{x=0}^{z} \frac{e^{-\lambda_1} \lambda_1^x }{x!} \frac{e^{-\lambda_2} \lambda_2^{z-x} }{(z-x)!} \]
\[ = \frac{e^{-(\lambda_1 + \lambda_2 )}(\lambda_1 + \lambda_2)^z}{z!} \sum_{x=0}^{z}\frac{z!}{x!(z-x)!}\left( \frac{\lambda_1}{\lambda_1+\lambda_2} \right)^x \left( \frac{\lambda_2}{\lambda_1+\lambda_2} \right)^{z-x} \]
二項分布の和は1になるので以下のように表される。
\[ = \frac{e^{-(\lambda_1 + \lambda_2 )}(\lambda_1 + \lambda_2)^z}{z!} \]
このように表されることを再生性があると呼ぶ。

5.超幾何分布 N個の製品からなる仕切りのなかで、M個の不良品があるとする。
非復元抽出でn個を抽出した際の、不良品の数をXとした際の確率分布は以下のように表される。

\[P(X=x)=\frac{{}_M \mathrm{C} _x \times {}_{N-M} \mathrm{C} _{n-x}}{{}_N \mathrm{C} _n} \]

xは非負の整数で \[max \{ 0, n -(N-M) \} \leq x \leq min \{ n, M \}\]
に従うものとする。

ここで製品の数Nが標本nに比べて十分に大きい場合を考える。
\[\frac{{}_M \mathrm{C} _x \times {}_{N-M} \mathrm{C} _{n-x}}{{}_N \mathrm{C} _n} \]
\[ = \frac{M!}{x!\left( M-x \right)!} \times \frac{\left( N – M \right)! }{\left( n-x\right)! \left[ N-M -\left( n-x\right) \right]!} \times \frac{n! \left(N-n\right)!}{N!} \]
\[ = \frac{\left[ M(M-1)\dots (M-x+1)\right] }{x!(n-x)! \times \left[ N(N-1)\dots (N-n+1) \right]}\]
\[ \times \left[ (N-M)(N-M-1)\dots (N-M-n+x+1)\right]\times n! \]
組み合わせを使ってまとめると、分母と分子の数はn個であるから、分母分子にn個だけ1/Nを掛けると以下のようになる。
\[ = \frac{{}_n \mathrm{C} _x \times \frac{M}{N} \left( \frac{M}{N} – \frac{1}{N} \right) \dots \left( \frac{M}{N} – \frac{x-1}{N} \right) }{1 \left( 1 – \frac{1}{N} \right) \dots \left( 1 – \frac{n-1}{N} \right) } \]
\[ \times \left( \frac{N-M}{N} \right) \times \left( \frac{N-M}{N} – \frac{1}{N} \right) \dots \left( \frac{N-M}{N} – \frac{n-x-1}{N} \right) \]

ここで \[ \theta = \frac{M}{N}\] から、 \[ M = N\theta\]
として代入すると、

\[ = \frac{{}_n \mathrm{C} _x \times \theta \left( \theta – \frac{1}{N} \right) \dots \left( \theta – \frac{x-1}{N} \right) }{1 \left( 1 – \frac{1}{N} \right) \dots \left( 1 – \frac{n-1}{N} \right) } \]

\[ \times \left( 1-\theta \right) \times \left( (1-\theta) – \frac{1}{N} \right) \dots \left( (1-\theta) – \frac{n-x-1}{N} \right) \]

となる。
ここで、Nの極限を取ると以下のように、分母が全て1になり、以下のように表される。
\[ \lim_{N\to\infty}\frac{{}_M \mathrm{C} _x \times {}_{N-M} \mathrm{C} _{n-x}}{{}_N \mathrm{C} _n} = {}_n \mathrm{C} _x \theta^x \left( 1 – \theta \right)^{n-x} \]
これは二項分布と同じ形となる。
つまり、超幾何分布において、製品の数が十分に大きいと二項分布と同じになる。

超幾何分布の平均
\[ E(X) = \sum_{x=0}^{n} x \frac{ {}_M \mathrm{C} _x \times {}_{N-M} \mathrm{C} _{n-x}}{{}_N \mathrm{C} _n} \]

\[ = \frac{1}{ {}_N \mathrm{C} _n } \sum_{x=0}^{n} x \frac{M!}{(M-x)!x!} \times \frac{(N-M)!}{ \left[ N-M-(n-x) \right]! (n-x)!}\]

\[ = \frac{M}{ {}_N \mathrm{C} _n} \sum_{x=0}^{n} \frac{(M-1)!}{\left[ (M-1)-(x-1) \right]!(x-1)!} \]

\[ \times \frac{\left[ (N-1)-(M-1) \right]!}{\left[ (N-1)-(M-1)-\left[(n-1)-(x-1)\right] \right]! \left[ (n-1)-(x-1) \right]!}\]

\[ = \frac{M}{ {}_N \mathrm{C} _n} \sum_{x=0}^{n} {}_{M-1} \mathrm{C} _{x-1} \times {}_{(N-1) – (M-1)} \mathrm{C} _{(n-1)-(x-1)} \]

\[ = \frac{M}{ \frac{N!}{(N-n)!n!} } \sum_{x=0}^{n} {}_{M-1} \mathrm{C} _{x-1} \times {}_{(N-1) – (M-1)} \mathrm{C} _{(n-1)-(x-1)} \]

\[ = \frac{nM}{ \frac{(N-1)!N}{\left[ (N-1)-(n-1)\right]!(n-1)!} } \sum_{x=0}^{n} {}_{M-1} \mathrm{C} _{x-1} \times {}_{(N-1) – (M-1)} \mathrm{C} _{(n-1)-(x-1)} \]

\[ = \frac{nM}{N} \sum_{x=0}^{n} \frac{ {}_{M-1} \mathrm{C} _{x-1} \times {}_{(N-1) – (M-1)} \mathrm{C} _{(n-1)-(x-1)} }{ {}_{N-1} \mathrm{C} _{n-1} } \]

超幾何分布の和は確率分布のため、1になることから、 \[ = \frac{nM}{N}\]
となる。これは二項分布の平均と同じとなる。

いちいち計算するのが面倒なので、二項係数の公式をここに載せておきます。

\[ {}_n \mathrm{C} _r = {}_n \mathrm{C} _{n-r} \]
\[r {}_n \mathrm{C} _r = n {}_{n-1} \mathrm{C} _{r-1}\]
\[ {}_n \mathrm{C} _r = {}_{n-1} \mathrm{C} _{r} + {}_{n-1} \mathrm{C} _{r-1}\]

超幾何分布の分散
\[E(X(X-1))= \sum_{x=0}^{n} x(x-1) \frac{ {}_M \mathrm{C} _x \times {}_{N-M} \mathrm{C} _{n-x}}{{}_N \mathrm{C} _n}\]

二項係数の公式より、

\[ = \sum_{x=0}^{n} (x-1) \frac{ M \times {}_{M-1} \mathrm{C} _{x-1} \times {}_{N-M} \mathrm{C} _{n-x} \times n }{ N \times {}_{N-1} \mathrm{C} _{n-1} } \]
\[ = \sum_{x=0}^{n} \frac{ M(M-1) \times {}_{M-2} \mathrm{C} _{x-2} \times {}_{(N-2)-(M-2)} \mathrm{C} _{(n-2)-(x-2)} \times n(n-1) }{ N(N-1) \times {}_{N-2} \mathrm{C} _{n-2}} \]
超幾何分布の和が1であることから、 \[ n(n-1) \frac{M(M-1)}{N(N-1)} \]

\[V(X)=E(X^2)-[ E(X) ]^2\] \[ =E[X(X-1)] + E(X) -[ E(X) ]^2\]
\[ = n(n-1) \frac{M(M-1)}{N(N-1)}+ \frac{nM}{N} – \frac{n^2M^2}{N^2} \]
\[ = \frac{nM}{N} \left[ (n-1) \frac{M-1}{N-1} + 1 – \frac{nM}{N} \right] \]
\[ = \frac{nM}{N} \left( 1 – \frac{M}{N} \right) \left( \frac{N-n}{N-1} \right) \]

超幾何分布の平均は二項分布と同じであったが、分散に関しては、
\[ \left( \frac{N-n}{N-1} \right) \] だけ異なる。

6.幾何分布
復元抽出で、不良品が出るまで検査した際の観測された良品の数Xの確率分布は以下の幾何分布に従う。

\[P(X=x)=\theta ( 1-\theta)^x \]

幾何分布は無記憶性という性質を持っており、それは幾何分布のみが持つとされている。無記憶性はある時点から先に時点を進めた際に、過去の時点の影響が残らないことを指している。

\[P(X=x+h | X \geq x) = \frac{P(X=x+h)}{ \sum_{y=x}^{\infty} P(X=y) }\]
\[ = \frac{ \theta ( 1-\theta)^{x+h} }{ \sum_{y=x}^{\infty} \theta ( 1-\theta)^y } \]
\[ = \frac{ \theta ( 1-\theta)^{h} }{ \sum_{y=x+1}^{\infty} \theta ( 1-\theta)^y } \]
超幾何分布の和は1であるから、 \[ = \theta ( 1-\theta)^h \]
\[ = P(X=h) \]

幾何分布の平均 \[ E(X) = \sum_{x=0}^{\infty} x \theta ( 1-\theta)^x \]
\[ = \sum_{x=1}^{\infty} x \theta ( 1-\theta)^x \]
\[ = \theta \sum_{x=1}^{\infty} x ( 1-\theta)^x \]
\[ = \theta \frac{d \sum_{x=1}^{\infty} (1-\theta)^x}{d(1-\theta)}\times (1-\theta) \]
無限等比級数の和の公式より、
\[ = \theta \frac{d \left( \frac{1-\theta}{1-(1-\theta)} \right) }{d(1-\theta)}\times (1-\theta) \]
\[ = \theta \frac{d \frac{1-\theta}{\theta}}{d \theta} \times \frac{d \theta}{d(1-\theta)}\times (1-\theta)\]
\[ = \theta \frac{-\theta – (1 – \theta)}{\theta^2} \times \frac{1}{-1}\times (1-\theta)\]
\[ = \frac{1-\theta}{\theta}\]

幾何分布に関しては、べき級数の和を使うことが多いので、毎回書くのも大変なためここで紹介しておく。

\[ 1 + r + r^2 + r^3 + \dots = \sum_{k=0}^{\infty} r^k = \frac{1}{1-r}\]
両辺をrで微分すると、
\[ 1 + 2r + 3\times r^2 + \dots = \sum_{k=1}^{\infty} kr^{k-1} = \frac{1}{(1-r)^2}\]
さらに両辺をrで微分すると、
\[ 2 + 3\times2 r + 4\times 3 r^2 + \dots = \sum_{k=2}^{\infty} (k-1)kr^{k-2} = \frac{2}{(1-r)^3}\]
となる。

幾何分布の分散
\[ E(X(X-1)) = \sum_{x=0}^{\infty} x(x-1) \theta ( 1-\theta)^x \]
\[ = \theta (1-\theta)^2 \sum_{x=2}^{\infty} x(x-1) ( 1-\theta)^x \]
べき級数の和を用いると、
\[ = \theta (1-\theta)^2 \frac{2}{\left[ 1 – (1-\theta) \right]^3 }\]
\[ = \frac{2(1-\theta)^2}{\theta^2} \]

\[V(X)=E(X^2)-[ E(X) ]^2 =E[X(X-1)] + E(X) -[ E(X) ]^2 \]
\[ = \frac{2(1-\theta)^2}{\theta^2} + \frac{1-\theta}{\theta} – \frac{(1-\theta)^2}{\theta^2} = \frac{(1-\theta)^2 + \theta(1-\theta)}{\theta^2} \]
\[ = \frac{1-\theta}{\theta^2}\]

θの絶対値は1以下なので、幾何分布においては、分散が平均よりも大きくなることがわかる。

7.負の二項分布
r個の不良品が見つかるまでに観測した良品の数Xが従う確率分布で、以下のように表される。

\[P(X=x)={}_{r+x-1} \mathrm{C} _x \theta^r (1-\theta)^x , x=0,1,2,\dots\]
負と呼ばれる所以は、以下のように組み合わせを負で表現できるところにある。

以下では実際に負で表現できるかを示す。
\[P(X=x)={}_{-r} \mathrm{C} _x \theta^r(\theta – 1)^x\]

\[ {}_{r+x-1} \mathrm{C} _x = \frac{(r+x-1)(r+x-2)\dots(r+1)r}{x!} \]
分子の数はx個あるので、おのおの-1を掛けると
\[ = (-1)^x \frac{(-r)(-r-1)\dots(-r-(x-2))(-r-(x-1))}{x!}\]
\[ = (-1)^x \frac{(-r)!}{(-r-x)!x!}\]
\[ = (-1)^x {}_{-r} \mathrm{C} _x \] よって、
\[P(X=x)=(-1)^x {}_{-r} \mathrm{C} _x \theta^r (1-\theta)^x \]
\[ =(-1)^x {}_{-r} \mathrm{C} _x \theta^r (\theta-1)^x \]

負の二項分布の平均
\[E(X) = \sum_{x=0}^{\infty} x \times {}_{r+x-1} \mathrm{C} _x \theta^r (1-\theta)^x \]

\[ =\sum_{x=1}^{\infty} \frac{(r+x-1)!\theta^r (1-\theta)^x}{(x-1)!(r-1)!} \]
ここでx = y + 1 として
\[ =\sum_{y=0}^{\infty} \frac{(r+y)!\theta^r (1-\theta)^{y+1}}{(y+1-1)!(r-1)!} \]
\[ = \frac{r(1-\theta)}{\theta} \sum_{y=0}^{\infty} \frac{(r+y)! \theta^{r+1} (1-\theta)^{y}}{y!r!} \]
\[ = \frac{r(1-\theta)}{\theta} \sum_{y=0}^{\infty} \frac{(r+y)(r+y-1)\dots (r+1) \theta^{r+1} (1-\theta)^{y}}{y!} \]
\[ = \frac{r(1-\theta)}{\theta} \sum_{y=0}^{\infty} {}_{r+y} \mathrm{C} _{y} \theta^{r+1} (1-\theta)^y \]
ここで負の二項分布の和は1であることから、
\[ = \frac{r(1-\theta)}{\theta} \] となる。

負の二項分布の分散
\[ E(X(X-1)) = \sum_{x=0}^{\infty} x(x-1) \times {}_{r+x-1} \mathrm{C} _x \theta^r (1-\theta)^x \]

\[ = \sum_{x=2}^{\infty} \frac{(x+r-1)(x+r-2)\dots r}{(x-2)!} \theta^r (1-\theta)^x \]

ここでx = y + 2 として

\[ = \sum_{y=0}^{\infty} \frac{(y+r+1)(y+r)\dots r}{y!} \theta^r (1-\theta)^{y+2} \]
\[ = \frac{r(r+1)(1-\theta)^2}{\theta^2} \sum_{y=0}^{\infty} \frac{(y+r+1)(y+r)\dots (r+2)}{y!} \theta^{r+2} (1-\theta)^{y} \]
\[ = \frac{r(r+1)(1-\theta)^2}{\theta^2} \sum_{y=0}^{\infty} {}_{r+y+1} \mathrm{C} _{y} \theta^{r+2} (1-\theta)^y \]
ここで負の二項分布の和は1であることから、
\[ = \frac{r(r+1)(1-\theta)^2}{\theta^2} \]

\[V(X)=E(X^2)-[ E(X) ]^2 =E[X(X-1)] + E(X) -[ E(X) ]^2 \]
\[ = \frac{r(r+1)(1-\theta)^2}{\theta^2} + \frac{r(1-\theta)}{\theta} – \frac{r^2(1-\theta)^2}{\theta^2} \]
\[ = \frac{(1-\theta)^2r + (1-\theta)\theta r}{\theta^2} \]
\[ = \frac{(1-\theta)\left[ (1-\theta)r + \theta r \right]}{\theta^2} \]
\[ = \frac{r(1-\theta)}{\theta^2} \]

θの絶対値は1以下なので、負の二項分布においては、分散が平均よりも大きくなることがわかる。


\end{document}
